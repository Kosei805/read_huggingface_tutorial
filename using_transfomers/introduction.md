# はじめに

このノートブックでは、トランスフォーマーモデルの概念を掘り下げ、Transformerライブラリを探求します。その特徴である使用の容易さ、柔軟性、簡潔さについて説明します。

## 第1章：トランスフォーマーモデルの理解

トランスフォーマーモデルは、主に自然言語処理（NLP）のタスクで使用される大規模なニューラルネットワークアーキテクチャです。数百万から数十億のパラメータから成り、NLPの分野を革新しました。

## 第2章：Transformerライブラリ

Transformerライブラリは、トランスフォーマーモデルのトレーニングと展開を簡素化することを目的としています。トランスフォーマーモデルのロード、トレーニング、保存のための単一のAPIを提供します。その主な特徴を探ってみましょう。

### 使用の容易さ

たった2行のコードで、最先端のNLPモデルをダウンロードし、ロードし、推論に使用することができます。

### 柔軟性

トランスフォーマーモデルは、単純なPyTorchまたはTensorFlowのクラスに基づいて構築されており、それぞれの機械学習フレームワークの他のモデルと同様に扱うことができます。

### 簡潔さ

ライブラリは不要な抽象化を避け、コードを理解しやすく、ハッキングしやすくします。各モデルには独自の層があり、他のモデルに影響を与えることなく簡単に実験できます。

## 第3章：エンドツーエンドの例

第1章で紹介されたpipeline()関数をモデルとトークナイザーを一緒に使用して再現するエンドツーエンドの例から始めます。

## 第4章：モデルAPI

次に、モデルAPIについて詳しく説明し、モデルと構成クラスを探求し、モデルをロードして数値入力を処理し、予測を出力する方法を示します。

## 第5章：トークナイザーAPI

次に、トークナイザーAPIを探索します。これは、テキストから数値入力への変換と、必要に応じてテキストへの変換を処理します。

## 第6章：バッチ処理

準備されたバッチで複数の文をモデルに送信する方法を示します。

## 第7章：結論

最後に、高レベルのtokenizer()関数を詳しく見て、全体をまとめます。

