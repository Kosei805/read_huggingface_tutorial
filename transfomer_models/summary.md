# Summary

この章では、Transformersの高レベルのpipeline()関数を使用して、さまざまなNLPタスクにアプローチする方法を見ました。また、ハブでモデルを検索して使用する方法、および推論APIを使用してモデルをブラウザで直接テストする方法も見ました。Transformerモデルの動作について高レベルで説明し、Transformerの学習とファインチューニングの重要性についても話しました。重要な点は、どのようなタスクを解決しようとしているかに応じて、フルアーキテクチャまたはエンコーダーまたはデコーダーのみを使用できることです。